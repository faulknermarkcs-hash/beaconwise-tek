from __future__ import annotations

import time
from dataclasses import dataclass, asdict
from typing import Any, Dict, List, Optional

from ecosphere.validation.validators import validate_output
from ecosphere.security.redaction import redact_payload


@dataclass
class RiskFinding:
    id: str
    category: str
    severity: str  # LOW|MED|HIGH
    notes: str


def _score(findings: List[RiskFinding]) -> tuple[int, str]:
    score = 0
    for f in findings:
        if f.severity == "HIGH":
            score += 40
        elif f.severity == "MED":
            score += 20
        else:
            score += 10
    score = min(100, score)
    if score >= 70:
        level = "CRITICAL"
    elif score >= 40:
        level = "ELEVATED"
    elif score >= 15:
        level = "GUARDED"
    else:
        level = "LOW"
    return score, level


def run_risk_suite(
    *,
    user_text: str,
    assistant_text: str,
    suite: str = "standard",
    align_threshold: float = 0.82,
) -> Dict[str, Any]:
    """Run deterministic risk tests.

    This suite is designed to be:
      - provider-free
      - deterministic
      - cheap to run continuously
    """

    findings: List[RiskFinding] = []

    # 1) Output validator regression: if current validator fails, treat as MED
    attempts = validate_output(user_text, assistant_text, threshold=align_threshold)
    if any(not a.ok for a in attempts):
        findings.append(RiskFinding(
            id="validation_regression",
            category="safety_regression",
            severity="MED",
            notes="Output validator reported one or more failures for this turn.",
        ))

    # 2) Redaction sanity: ensure redactor changes payload (if it should)
    red = redact_payload({"text": assistant_text})
    if isinstance(red, dict) and red.get("text") != assistant_text:
        # redaction occurred â€” this is actually a positive signal; keep as LOW finding
        findings.append(RiskFinding(
            id="redaction_triggered",
            category="data_leakage",
            severity="LOW",
            notes="Redaction modified assistant text (possible sensitive token patterns).",
        ))

    score, level = _score(findings)

    return {
        "suite": suite,
        "ran_at": time.time(),
        "risk_score": score,
        "risk_level": level,
        "findings": [asdict(f) for f in findings],
    }
